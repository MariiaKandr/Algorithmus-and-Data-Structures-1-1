# Алгоритмы сортировки 

Материал оформлен на основе рабочей тетради «Алгоритмы — Рабочая тетрадь 4» (семестр 1, 2025–2026). 

---

## Содержание

1. [Введение — базовые понятия](#введение---базовые-понятия)
2. [Таблица сложности и свойства](#таблица-сложности-и-свойства)
3. [Операция `swap` — пример и измерения (Пример 1)](#операция-swap---пример-и-измерения)
4. [Пузырьковая сортировка (Bubble Sort)](#пузырьковая-сортировка-bubble-sort)
5. [Шейкерная сортировка (Cocktail / Shaker)](#шейкерная-сортировка-cocktail--shaker)
6. [Сортировка вставками (Insertion Sort)](#сортировка-вставками-insertion-sort)
7. [Сортировка выбором (Selection Sort)](#сортировка-выбором-selection-sort)
8. [Сортировка Шелла (Shell Sort)](#сортировка-шелла-shell-sort)
9. [Гномья сортировка (Gnome Sort)](#гномья-сортировка-gnome-sort)
10. [Функции + измерения времени](#функции--измерения-времени)
11. [Бинарная вставка — улучшение Insertion](#бинарная-вставка----улучшение-insertion)
12. [Примечания и рекомендации](#примечания-и-рекомендации)

---

# Введение — базовые понятия

**Сортировка** — алгоритм, упорядочивающий набор элементов по некоторому критерию (обычно по ключу: возрастание/убывание). В программировании сортировки — одна из базовых операций: поиска, слияния, индексации, удаления дубликатов и т.д.

Ключевые вопросы: корректность, сложность (время и память), стабильность и пригодность для конкретного набора данных.

---

# Таблица сложности и свойства

| Алгоритм          |                     Среднее время | Худшее время | Память | Стабильность | Примечание                       |
| ----------------- | --------------------------------: | -----------: | -----: | -----------: | -------------------------------- |
| Bubble            |                             O(n²) |        O(n²) |   O(1) |           Да | прост и учебен                   |
| Cocktail (Shaker) |                             O(n²) |        O(n²) |   O(1) |           Да | Bi-directional bubble            |
| Insertion         |                             O(n²) |        O(n²) |   O(1) |           Да | хорошо для почти отсортированных |
| Selection         |                             O(n²) |        O(n²) |   O(1) |          Нет | минимизирует число обменов       |
| Shell             | зависит от последовательности gap |            — |   O(1) |          Нет | намного быстрее на средних n     |
| Gnome             |                             O(n²) |        O(n²) |   O(1) |           Да | реализация ↔ один цикл (можно)   |



---

## 2. Классификация алгоритмов сортировки 

1. **По модели сравнений**

   * *Сравнительные*: Quicksort, Mergesort, Heapsort, Insertion, Selection, Bubble и т.д. Нижняя граница сравнений — Ω(n log n) для сортировки произвольных ключей.
   * *Немного сравнивающие / не сравнивающие*: Counting sort, Radix sort — дают лучше O(n) при дополнительных предположениях (малограда или целые ключи в ограниченном диапазоне).

2. **По месту использования памяти**

   * *In-place* (на месте): Quicksort (обычно), Heapsort,Insertion — O(1) дополнительной памяти.
   * *Не in-place*: Mergesort (классический) — требует O(n) доп. памяти (хотя есть in-place варианты с усложнением).

3. **Стабильность**

   * *Стабильные*: Mergesort, Insertion, Bubble (в простых реализациях), std::stable_sort.
   * *Нестабильные*: Quicksort (обычные реализации), Heapsort, Selection.

4. **Внутренние vs внешние**

   * *Внутренние* — весь массив помещается в ОЗУ (обычные алгоритмы).
   * *Внешние* — данные слишком велики для ОЗУ — используются внешние алгоритмы (external merge sort).

---

## 3. Какие сортировки реально используют на практике

* **std::sort (C++)** — реализация Introsort: быстрая комбинация QuickSort + HeapSort + Insertion; работает in-place, нестабильна, среднее O(n log n), худшее O(n log n) (гарантируется переходом на HeapSort).
* **std::stable_sort** — обычно реализован через Merge Sort; стабильный, требует O(n) доп. памяти, O(n log n) время.
* **Quicksort** — быстрый на среднем, простая реализация, но надо правильно выбирать pivot (и иногда использовать случайный pivot или медиану).
* **Merge sort** — стабильный и предсказуемый; часто используется для `stable_sort` и внешних сортировок.
* **Heapsort** — гарантированное O(n log n) и in-place; редко используется как основная реализация std::sort, но полезен если нужно ограничение памяти и худший случай O(n log n).
* **Counting / Radix sort** — для ключей типа int/string при ограниченном диапазоне — линейные по времени в практических сценариях.
* **Hybrid алгоритмы (Introsort)** — реальны и широко используются (например — std::sort).

---

## 4. Где готовые реализации в C++

* `#include <algorithm>`

  * `std::sort(begin, end, comp)` — Introsort (обычно).
  * `std::stable_sort(begin, end, comp)` — стабильный (merge).
  * `std::partial_sort`, `std::nth_element`, `std::is_sorted`, `std::sort_heap`, `std::make_heap`, `std::push_heap`, `std::pop_heap`.
* `#include <iterator>` — для работы с итераторами (RandomAccessIterator требуется для std::sort).
* `#include <functional>` — для предикатов/функторов.

---

## 5. Три типа «указателей» в C++ и их влияние на код

Пользователи часто выделяют **3 классических подхода** к доступу/ссылкам на объекты:

1. **Raw pointers (`T*`)**

   * Могут быть `nullptr`, копируются по адресу.
   * Нужны для низкоуровневого управления памятью, C-совместимости.
   * Требуют заботы об владении/освобождении памяти (опасность утечек / двойного удаления).
   * Влияние на сортировки: сортировка указателей (обмен адресов) — очень дешёвая операция; но сортируя указатели, нужно помнить о сроке жизни объектов.

2. **References (`T&` / `T&&`)** (не совсем указатель, но pointer-like)

   * Не могут быть `nullptr` (если только не использовать ссылку на невалидный объект).
   * Удобны для передачи объектов в функции без копирования.
   * Не хранятся в контейнерах (нельзя `std::vector<T&>`), поэтому для контейнерной сортировки обычно используются указатели или smart pointers.

3. **Smart pointers (`std::unique_ptr`, `std::shared_ptr`, `std::weak_ptr`)**

   * `unique_ptr<T>` — единоличное владение; перемещаемый, не копируемый.
   * `shared_ptr<T>` — подсчёт ссылок; копирование инкрементирует счётчик; возможно циклическое удержание объектов (требует weak_ptr для разрыва циклов).
   * `weak_ptr<T>` — не владеет объектом; проверяется через `.lock()`.
   * Влияние: сортировка контейнера `std::vector<std::unique_ptr<T>>` требует использования `std::move` и компаратора, работающего по `*ptr` или по ключу; сортировка smart pointers дешевле по копированию адреса, но `shared_ptr` несёт накладные расходы на атомарный/неатомарный инкремент/декремент счётчика (в многопоточных сценариях — дополнительная стоимость).

Дополнительно:

* **const correctness**: `T* const` vs `const T*` — влияет на то, что можно менять при сортировке.
* **Pointer stability**: сортировка ссылок/указателей не меняет объекты, а только их порядок — это полезно, если объекты тяжёлые для копирования.

---

# Операция `swap` — пример и измерения (Пример 1)


Ниже — два способа обмена двух элементов: использование `std::swap` и собственная функция `my_swap`. Также пример замера времени.

```cpp
// swap_from_.cpp
#include <iostream>
#include <chrono>     // Для оценки времени работы функции
#include <algorithm>  // std::swap
#include <cstdlib>    // rand, srand
#include <ctime>      // time
#include <clocale>    // setlocale

using namespace std;

void my_swap(int& x, int& y) { // Собственная функция swap()
    int tmp = x;
    x = y;
    y = tmp;
}

int main() {
    setlocale(LC_ALL, "Russian");
    srand((unsigned)time(NULL));        // Для генератора случайных чис
    // srand((unsigned)rand());         // в скриншоте была вторая srand, но она не нужна

    int count = 0; // Переменная для хранения размера массива
    cout << "Введите размер массива (больше 10): ";
    cin >> count;

    if (count <= 5) {
        cout << "Размер должен быть не меньше 6, чтобы были элементы с индексами 2 и 5.\n";
        return 1;
    }

    int* num = new int[count]; // Массив
    for (int i = 0; i < count; i++) {
        num[i] = rand() % 31; // заполнение массива числами от 0 до 30
    }

    // Вывод массива
    cout << "Ваш массив:" << endl;
    for (int i = 0; i < count; i++) {
        cout << num[i] << " ";
    }
    cout << endl << endl;

    // Перестановка 2 и 5 элементов с помощью std::swap
    auto begin1 = chrono::steady_clock::now(); // Старт замера работы функции
    std::swap(num[2], num[5]);
    auto end1 = chrono::steady_clock::now();
    auto dur1 = chrono::duration_cast<chrono::microseconds>(end1 - begin1).count();

    cout << "После std::swap (поменяны элементы с индексами 2 и 5):" << endl;
    for (int i = 0; i < count; i++) cout << num[i] << " ";
    cout << endl;
    cout << "Время std::swap: " << dur1 << " мкс" << endl << endl;

    // Снова перемешаем массив случайными значениями, чтобы сравнение было корректным:
    for (int i = 0; i < count; i++) num[i] = rand() % 31;

    // Перестановка 2 и 5 элементов с помощью my_swap
    auto begin2 = chrono::steady_clock::now();
    my_swap(num[2], num[5]);
    auto end2 = chrono::steady_clock::now();
    auto dur2 = chrono::duration_cast<chrono::microseconds>(end2 - begin2).count();

    cout << "После my_swap (поменяны элементы с индексами 2 и 5):" << endl;
    for (int i = 0; i < count; i++) cout << num[i] << " ";
    cout << endl;
    cout << "Время my_swap: " << dur2 << " мкс" << endl << endl;

    delete[] num;
    return 0;
}
```

**Примечание:** Разница часто минимальна, компилятор может инлайнить `std::swap` или оптимизировать пользовательский код — измеряйте корректно (чтобы не оптимизировалось в пустоту).

---

# Пузырьковая сортировка (Bubble Sort)

**Идея:** многократные проходы по массиву, при которых соседние элементы сравниваются и при необходимости меняются местами. После каждого прохода последний элемент — максимальный среди неотсортированных.

![bubble sort gif](http://gifimage.net/wp-content/uploads/2017/10/bubble-sort-gif-9.gif)
![image](https://github.com/user-attachments/assets/b70deb9c-9d24-463e-89bf-f2c185bc4005)

**Асимптотика:**

сложность в худшем  | сложность в среднем | сложность в лучшем |
--------------------|---------------------|--------------------|
O(n<sup>2</sup>)    | O(n<sup>2</sup>)    | O(n)               |

**Расход памяти:** O(1). Дополнительной памяти не требуется.

Алгоритм устойчив. На практике может использоваться лишь для сортировки маленьких массивов. И в этом случае лучше взять классическую сортировку, а не её модификацию.


**Псевдокод:**

```
for i = 0 to n-2
  swapped = false
  for j = 0 to n-2-i
    if a[j] > a[j+1] then swap(a[j], a[j+1]); swapped = true
  if not swapped then break
```

**C++ реализация:**

```cpp
void bubble_sort(std::vector<int>& a) {
    int n = a.size();
    for (int i = 0; i < n-1; ++i) {
        bool swapped = false;
        for (int j = 0; j < n-1-i; ++j) {
            if (a[j] > a[j+1]) {
                std::swap(a[j], a[j+1]);
                swapped = true;
            }
        }
        if (!swapped) break;
    }
}
```

**Пример:**
Input: `[5, 1, 4, 2, 8]` → Output: `[1,2,4,5,8]`

---

# Шейкерная сортировка (Cocktail / Shaker) 

Устанавливаем левую и правую границы сортируемой области массива. Поочерёдно просматриваем массив справа налево и слева направо. На очередной итерации при достижении правой границы 
сдвигаем её на предыдущий элемент (-1) и движемся справа налево, при достижении левой границы сдвигаем её на следующий элемент (+1) и двигаемся слева направо.

![shaker sort gif](https://upload.wikimedia.org/wikipedia/commons/e/ef/Sorting_shaker_sort_anim.gif)

**Асимптотика:**

сложность в худшем  | сложность в среднем      | сложность в лучшем    |
--------------------|--------------------------|-----------------------|
O(n<sup>2</sup>)    |зависит от выбранных шагов| O(n log<sup>2</sup> n)|
 **худший случай**: отсортированный в обратном порядке массив| - |**лучший случай**:  отсортированный массив| 

**Расход памяти:** O(1). Дополнительной памяти не требуется.

Алгоритм устойчив. 


**Псевдокод:**

```
left = 0; right = n-1
while left < right:
  last = 0
  for i = left to right-1:
    if a[i] > a[i+1]: swap; last = i
  right = last
  for i = right downto left+1:
    if a[i-1] > a[i]: swap; last = i
  left = last
```

**C++ реализация:**

```cpp
void shaker_sort(std::vector<int>& a) {
    int left = 0, right = (int)a.size() - 1;
    while (left < right) {
        int last = 0;
        for (int i = left; i < right; ++i) {
            if (a[i] > a[i+1]) { std::swap(a[i], a[i+1]); last = i; }
        }
        right = last;
        for (int i = right; i > left; --i) {
            if (a[i-1] > a[i]) { std::swap(a[i-1], a[i]); last = i; }
        }
        left = last;
    }
}
```

---

# Сортировка вставками (Insertion Sort)

**Идея:** строим отсортированную часть слева; каждый следующий элемент вставляем в нужное место в уже отсортированной части.

![image](https://github.com/user-attachments/assets/d4bbdc32-669c-4245-a6b2-159d0bd21301)


**Псевдокод:**

```
for i = 1 to n-1
  key = a[i]
  j = i-1
  while j >= 0 and a[j] > key
    a[j+1] = a[j]; j = j-1
  a[j+1] = key
```

**C++ реализация:**

```cpp
void insertion_sort(std::vector<int>& a) {
    for (int i = 1; i < (int)a.size(); ++i) {
        int key = a[i];
        int j = i - 1;
        while (j >= 0 && a[j] > key) {
            a[j+1] = a[j];
            --j;
        }
        a[j+1] = key;
    }
}
```

**Примечание:** годится для почти отсортированных данных.

---

# Сортировка выбором (Selection Sort) 

**Идея:** на каждой итерации выбираем минимальный элемент в неотсортированной части и ставим его на следующую позицию.

![selection sort gif](https://upload.wikimedia.org/wikipedia/commons/9/94/Selection-Sort-Animation.gif)

**Асимптотика:**

сложность в худшем  | сложность в среднем | сложность в лучшем |
--------------------|---------------------|--------------------|
O(n<sup>2</sup>)    | O(n<sup>2</sup>)    | O(n<sup>2</sup>)   |

**Расход памяти:** O(1). Дополнительной памяти не требуется.

Алгоритм неустойчив.

**Псевдокод:**

```
for i = 0 to n-2
  min_idx = i
  for j = i+1 to n-1
    if a[j] < a[min_idx] then min_idx = j
  swap(a[i], a[min_idx])
```

**C++ реализация:**

```cpp
void selection_sort(std::vector<int>& a) {
    int n = a.size();
    for (int i = 0; i < n-1; ++i) {
        int min_idx = i;
        for (int j = i+1; j < n; ++j)
            if (a[j] < a[min_idx]) min_idx = j;
        std::swap(a[i], a[min_idx]);
    }
}
```

**Примечание:** количество обменов минимальное (≤ n), но сравнений — O(n²). Нестабильна.

---

# Сортировка Шелла (Shell Sort)

**Идея:** cравниваем элементы находящиеся друг от друга на некотором расстоянии (шаге). В алгоритме два цикла. Внутренний переставляет элементы. Внешний служит для изменения шага, через который внутренний цикл элементы будет переставлять. Шаг постепенно сокращается до 1 (минимальное расстояние между двумя элементами) - и тогда алгоритм Шелла превращается в 
обычную сортировку вставками.

![shell sort gif](https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Shellsort-ru.svg/600px-Shellsort-ru.svg.png)

**Асимптотика:**

сложность в худшем  | сложность в среднем | сложность в лучшем |
--------------------|---------------------|--------------------|
O(n<sup>2</sup>)    | O(n<sup>2</sup>)    | O(n)               |
 **худший случай**: неудачный выбор шага| - |**лучший случай**: массив уже отсортирован в правильном порядке| 

**Расход памяти:** O(1). Дополнительной памяти не требуется.

Алгоритм неустойчив.

**Простая стратегия gap:** `gap = n/2; while (gap > 0) { ...; gap /= 2; }`

**C++ реализация (простая версия):**

```cpp
void shell_sort(std::vector<int>& a) {
    int n = a.size();
    for (int gap = n/2; gap > 0; gap /= 2) {
        for (int i = gap; i < n; ++i) {
            int tmp = a[i];
            int j = i;
            while (j >= gap && a[j-gap] > tmp) {
                a[j] = a[j-gap];
                j -= gap;
            }
            a[j] = tmp;
        }
    }
}
```

**Примечание:** эффективность сильно зависит от последовательности gap (на практике используют Хиббарда, Седжвика и др.).

---

# Гномья сортировка (Gnome Sort) 

**Идея:** элемент «шагает» влево до своего места, при нарушении порядка — обмен и шаг назад; иначе шаг вперед. Можно реализовать одним циклом `while` — это условие задания (не более одного цикла).

![image](https://github.com/user-attachments/assets/c43f3b35-480b-431d-9a79-246f5339f510)

**Одноцикловая реализация (соответствует требованию «не более одного цикла»):**

```cpp
void gnome_sort(std::vector<int>& a) {
    int n = a.size();
    int i = 1;
    while (i < n) {
        if (i == 0 || a[i-1] <= a[i]) {
            ++i;
        } else {
            std::swap(a[i-1], a[i]);
            --i;
        }
    }
}
```

**Примечание:** это действительно один цикл `while` — внутри присутствуют только условные переходы и один обмен.

---
# Quick Sort (быстрая сортировка)
Выбираем некоторый опорный элемент (например, средний). После этого разбиваем исходный массив на три части: элементы эквивалентные опорному, меньше, больше опорного.
Рекурсивно вызовемся от большей и меньшей частей. В итоге получим отсортированный массив, так как каждый элемент меньше опорного стоял раньше каждого большего опорного. 

![quick sort gif](https://upload.wikimedia.org/wikipedia/commons/f/fe/Quicksort.gif)

**Асимптотика:**

сложность в худшем  | сложность в среднем | сложность в лучшем |
--------------------|---------------------|--------------------|
O(n<sup>2</sup>)    | O(n log n)          | O(n)               |
 **худший случай**: если опорный элемент наименьший или наибольший из всех, то каждый раз массив разбивается на подмассивы размерами 1 и n-1 | - |**лучший случай**: массив постоянно разбивается опорным элементом на две раные части | 

**Расход памяти:** В общем случае O(log n). При неудачных подборках опорного элемнта O(n) - здесь память будет расходоваться не на создание новых вспомогательных массивов,
а на рекурсию, хранение адресов возврата и локальных переменных.

Алгоритм неустойчив (неудачные входные данные могут привести к значительному увеличению времени работы и расхода памяти). 
Является одним из самых быстродействующих алгоритмов, однако для массивов с небольшим количеством элементом может оказаться малоэффективным. 

# Counting Sort (сортировка подсчётом)
Проходимся по массиву и подсчитываем количество вхождений каждого элемента. После проходим по массиву значений и выводим каждое число столько раз, сколько нужно.

![counting sort gif](https://gabrielghe.github.io/assets/themes/images/2016-03-09-counting-sort.gif)

**Асимптотика:**

сложность в худшем  | сложность в среднем | сложность в лучшем |
--------------------|---------------------|--------------------|
O(n)                | O(n)                | O(n)               |

**Расход памяти:** O(1). Дополнительной памяти не требуется.

Алгоритм устойчив. Применение сортировки подсчётом целесообразно лишь тогда, когда массив состоит из целочисленных, положительных чисел.

# Merge Sort (сортировка слиянием)
Исходный массив делится надвое на всё меньшие подмассивы, пока количество элементов в очередных не станет равным 2 или 1. 
Если в подмассиве 2 элемента, то он упорядочивается банальным сравнением. А подмассив из одного элемента по своей сути является упорядоченным. Затем происходит обратный процесс - слияние подмассивов. 
Поскольку подмассивы к этому времени являются упорядоченными, то можем сравнивать лишь элементы, стоящие в их начале.

![merge sort gif](http://gifimage.net/wp-content/uploads/2017/10/merge-sort-gif-5.gif)

**Асимптотика:**

сложность в худшем  | сложность в среднем | сложность в лучшем |
--------------------|---------------------|--------------------|
O(n log n)          | O(n log n)          | O(n log n)         |

**Расход памяти:** O(n). Требует дополнительной памяти, примерно равной размеру исходного массива. Память расходуется на рекурсивный вызов и на постоянное создание вспомогательных подмассивов.

Алгоритм устойчив. На «почти отсортированных» массивах работает столь же долго, как на хаотичных.

# Heap Sort (пирамидальная сортировка)
Строим на основе неотсортированного массива так называемую двоичную кучу или пирамиду. В результате получается бинарное дерево каждый узел которого больше предыдущего, тем самым
на вершине дерева оказывается элемент с максимальным значением. Затем вершина дерева переставляется в конец, откуда и будет выстраиваться отсортированный подмассив. А среди оставшихся элементов происходит ряд перестановок с целью восстановить дерево, чтобы в его вершине вновь оказался максимальный элемент из ещё не отсортированной части. 
Таким образом на первом месте постоянно оказывается один из самых "лёгких" элементов, который затем серией перестановок отправляется назад.

![heap sort gif](https://www.fluentcpp.com/wp-content/uploads/2018/01/ezgif-3-734bb0bf98.gif)

**Асимптотика:**

сложность в худшем  | сложность в среднем | сложность в лучшем |
--------------------|---------------------|--------------------|
O(n log n)          | O(n log n)          | O(n log n)         |

**Расход памяти:** O(1). Дополнительной памяти не требуется. Хотя в алгоритме присутствует рекурсивный вызов, но чтобы добраться до конца даже очень большого массива, рекурсий нужно мало, и они моментально закрываются.

Алгоритм устойчив. На почти отсортированных массивах работает столь же долго, как и на хаотических данных. Не работает на связанных списках и других структурах памяти последовательного доступа. 
Из-за сложности реализации выигрыш получается только на больших размерах массива.


---

# Функции измерения времени 

Рекомендации по измерениям:

* Используйте `std::chrono::high_resolution_clock`.
* Для честности измеряйте на копиях одного и того же исходного массива (чтобы каждый алгоритм получал одинаковые входные данные).
* Повторяйте измерение несколько раз и усредняйте (для уменьшения шума).
* Генерация данных:

  * маленький: `n = 100` — для медленных O(n²) алгоритмов —
  * большой: `n = 10000` (или меньше, если эти алгоритмы слишком медленные на вашей машине).
* Для Shell и т.п. можно использовать большие n — они лучше масштабируют.

**Примерный измерительный каркас:**

```cpp
#include <chrono>
#include <random>
#include <iostream>
#include <vector>
#include <functional>

long long time_run(std::function<void(std::vector<int>&)> f, std::vector<int> a, int repeats=3) {
    long long sum = 0;
    for (int r=0; r<repeats; ++r) {
        auto copy = a;
        auto start = std::chrono::high_resolution_clock::now();
        f(copy);
        auto end = std::chrono::high_resolution_clock::now();
        sum += std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();
    }
    return sum / repeats;
}

int main() {
    // generate base array
    std::mt19937 rng(42);
    std::uniform_int_distribution<int> d(0, 1'000'000);
    int n_small = 200, n_large = 10000;
    std::vector<int> small(n_small), large(n_large);
    for (int &x : small) x = d(rng);
    for (int &x : large) x = d(rng);

    // e.g. call time_run(bubble_sort, small)
}
```

---

# Бинарная вставка — улучшение Insertion 

**Идея:** при вставке элемента в отсортированную часть искать позицию бинарным поиском (O(log n)), но смещение элементов всё ещё O(n), поэтому сложность остаётся O(n²) в целом, но число сравнений уменьшается.

**Псевдокод (для поиска позиции):**

```
for i = 1..n-1:
  key = a[i]
  pos = binary_search_position(a[0..i-1], key)
  shift a[pos..i-1] right by 1
  a[pos] = key
```

**C++ реализация (binary insertion):**

```cpp
int binary_search_pos(const std::vector<int>& a, int key, int high) {
    int low = 0;
    while (low < high) {
        int mid = (low + high) / 2;
        if (a[mid] <= key) low = mid + 1;
        else high = mid;
    }
    return low;
}

void binary_insertion_sort(std::vector<int>& a) {
    int n = a.size();
    for (int i = 1; i < n; ++i) {
        int key = a[i];
        int pos = binary_search_pos(a, key, i);
        // shift right
        for (int j = i; j > pos; --j) a[j] = a[j-1];
        a[pos] = key;
    }
}
```

**Сравнение:** меньше сравнений — полезно, если сравнения дорогие; но смещения остаются.


# Примечания и рекомендации 

* Всегда тестируйте алгоритмы на различных входах: случайных, уже отсортированных, обратном порядке, с большим количеством одинаковых элементов.
* Для замеров используйте компиляцию с оптимизациями (`-O2`/`-O3`) и фиксированный сид для генератора случайных чисел.
* Обращайте внимание на стабильность алгоритмов, если сортируете структуры с ключом и связанной информацией.
* Для больших данных используйте эффективные алгоритмы: `std::sort` (обычно быстрый introsort) или `std::stable_sort` (слияние).
* Оформляйте код комментариями, поясняющими ключевые шаги алгоритма (особенно там, где логика не тривиальна).
Скажите, что предпочитаете — дам готовые файлы/архив или вставлю весь набор кодов прямо здесь.
